<!DOCTYPE html>
<html>
  <head>
    <title>Supplemental Resources – 6.861* Quantitative Methods for NLP – Advanced NLP</title>
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="Supplemental Resources" />
<meta name="author" content="Jacob Andreas and Chris Tanner" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Advanced NLP" />
<meta property="og:description" content="Advanced NLP" />
<meta property="og:site_name" content="6.861* Quantitative Methods for NLP" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Supplemental Resources" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","author":{"@type":"Person","name":"Jacob Andreas and Chris Tanner"},"description":"Advanced NLP","headline":"Supplemental Resources","url":"/supplemental"}</script>
<!-- End Jekyll SEO tag -->

    <meta content='text/html; charset=utf-8' http-equiv='Content-Type'>
<meta http-equiv='X-UA-Compatible' content='IE=edge'>
<meta name='viewport' content='width=device-width, initial-scale=1.0, maximum-scale=1.0'>


<meta property="og:description" content="Advanced NLP" />

<meta name="author" content="6.861* Quantitative Methods for NLP" />


<meta property="og:title" content="Supplemental Resources" />
<meta property="twitter:title" content="Supplemental Resources" />



<meta property="og:image" content="/images/mit_logo_resized.png"/>
<meta property="twitter:image" content="/images/mit_logo_resized.png"/>



    <link rel="stylesheet" type="text/css" href="//assets/style.css" />
    <link rel="alternate" type="application/rss+xml" title="6.861* Quantitative Methods for NLP - Advanced NLP" href="//feed.xml" />
    <link rel="canonical" href="/supplemental" />
    <link rel="icon" type = "image/png" href="images/favicon-32x32.png">
    <meta name="theme-color" content="#000000">
    
      <script async src="https://www.googletagmanager.com/gtag/js?id=G-T9GD1TN8YB"></script>
      <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
        gtag('config', 'G-T9GD1TN8YB');
      </script>


  </head>

  <body>
    <div id="bar"></div>
    <div class="wrapper-container">
      <div class="wrapper-masthead">
        <div class="container">
          <header class="masthead clearfix">
            <a href="//" class="site-avatar"><img src="//images/mit_logo_resized.png" alt="" /></a>

            <div class="site-info">
              <h1 class="site-name"><a href="//">6.861* Quantitative Methods for NLP</a></h1>
              <p class="site-description">Advanced NLP</p> 
            </div>

            <nav>
              <a href="//">Home</a>
              <a href="//schedule">Schedule</a>
              <a href="//project">Project</a>
              <a href="//syllabus">Syllabus</a>
              <a href="//FAQ">FAQ</a>
            </nav>
          </header>
          <div>
            <hr width="100%" size="1" color="#DCDCDC" noshade>
            <b>Fall 2024. Jacob Andreas, Chris Tanner</b>
            <br>
            <b><font color="#A4251A">T/TH 11:00am-12:30pm</font> in 32.123</b>
            <hr width="100%" size="1" color="#DCDCDC" noshade>
          </div>
        </div>
      </div>

      <div class="wrapper-main">
        <div id="main" role="main" class="container">
          <article class="page">
  <h1>Supplemental Resources</h1>
  <div class="entry">
    <p>Our intent is for this course to be as self-contained as possible. Toward this goal, the <strong>homework assignments</strong> will require you to apply the lecture content to solve problems, which involves significant <em>programming</em>. We expect students to already have a strong foundation in <em>programming</em> and <em>machine learning</em>. <span style="background-color: #FFFF00">If you do not already know how to program in PyTorch, you will need to pick it up as you go (as we will not have time in class to teach such).</span> These incredibly popular and useful frameworks make machine learning work significantly easier, so your experience with them will serve you well beyond this course. The <strong>research project</strong>, by design, will require you to take initiative to learn about NLP beyond what is covered in class, and to make a novel contribution.</p>

<p>There is a wealth of resources available online to help you fill in any gaps and to supplement your knowledge. It can be incredibly fruitful to read/hear others discuss the same content that we cover in lecture, as it not only reiterates what you already know, but it can provide an additional perspective to help you master the material. <strong>Thus, we highly encourage everyone to consider the following, phenomenal resources:</strong></p>

<h2 id="books">BOOKS</h2>
<h3 id="nlp">NLP</h3>
<ul>
  <li><strong><a href="https://web.stanford.edu/~jurafsky/slp3/">Speech and Language Processing</a></strong> by Jurafsky and Martin. 2020.</li>
  <li><a href="https://github.com/jacobeisenstein/gt-nlp-class/blob/master/notes/eisenstein-nlp-notes.pdf">Natural Language Processing</a> by Eisenstein. 2018.</li>
</ul>

<h3 id="machine-learning">MACHINE LEARNING</h3>
<ul>
  <li><strong><a href="https://d2l.ai/">Dive into Deep Learning</a></strong> by Zhang et al. 2020.</li>
  <li><strong><a href="https://www.statlearning.com/">An Introduction to Statistical Learning (aka ISLR) Edition 1</a></strong> by James et al.</li>
  <li><strong><a href="https://probml.github.io/pml-book/">Probabilistic Machine Learning Books 0, 1, and 2</a></strong> by Kevin Murphy 2012-2022</li>
  <li><a href="https://mml-book.github.io/">Mathematics for Machine Learning</a></li>
  <li><a href="https://www.microsoft.com/en-us/research/uploads/prod/2006/01/Bishop-Pattern-Recognition-and-Machine-Learning-2006.pdf">Pattern Recognition and Machine Learning</a> by Bishop.</li>
  <li><a href="https://www.researchgate.net/publication/351476107_The_Modern_Mathematics_of_Deep_Learning">The Modern Mathematics of Deep Learning</a> by Berner et al. May 2021.</li>
  <li><a href="https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf">Understanding Machine Learning: From Theory to Algorithms</a> by Shalev-Shwartz and Ben-David. 2014.</li>
  <li><a href="https://windowsontheory.org/2021/01/31/a-blitz-through-classical-statistical-learning-theory/">A blitz through classical statistical learning theory (blog)</a> by Boaz Barack. 2021.</li>
</ul>

<h3 id="math">MATH</h3>
<ul>
  <li><a href="https://drive.google.com/file/d/1VmkAAGOYCTORq1wxSQqy255qLJjTNvBI/view">Introduction to Probability</a> by Blitzstein and Hwang. 2019.</li>
</ul>

<hr width="100%" size="1" color="#DCDCDC" noshade="" />

<h2 id="courses-most-have-videos">COURSES (MOST HAVE VIDEOS)</h2>
<h3 id="nlp-1">NLP</h3>
<ul>
  <li><strong><a href="https://www.youtube.com/playlist?list=PLWnsVgP6CzadmQX6qevbar3_vDBioWHJL">UMass Amherst’s CS685: Advanced NLP</a></strong> by Mohit Iyyer</li>
  <li><a href="http://phontron.com/class/nn4nlp2021/schedule.html">CMU’s CS:11-747: Neural Networks for NLP (Spring 2021)</a> by Graham Neubig</li>
  <li><a href="https://www.mit.edu/~jda/teaching/6.864/sp21/">MIT’s 6.806: Natural Language Processing</a> by Jacob Andreas and Jim Glass</li>
  <li><a href="https://rycolab.io/classes/intro-nlp-s21/">ETH Zurich’s NLP (Spring 2021)</a> by Ryan Cotterell</li>
  <li><a href="https://docs.google.com/document/d/1uogW7KYD0aib1hJ3_FumIc2I9CIF7XfUfVkFDskibTU/edit#">NYU’s Natural Language Understanding and Computational Semantics (Spring 2020)</a> by Sam Bowman</li>
  <li><a href="https://www.youtube.com/watch?v=jfwqRMdTmLo">Michael Collins’ lecture about DeepLearning + NLP progress at large (YouTube)</a></li>
  <li><a href="https://harvard-iacs.github.io/CS287/">Harvard’s Advanced NLP course (Fall 2021)</a> by Chris Tanner</li>
</ul>

<h3 id="machine-learning-1">MACHINE LEARNING</h3>
<ul>
  <li><a href="https://www.youtube.com/playlist?list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU">Stanford CS229: Machine Learning</a> by Andrew Ng</li>
  <li><a href="http://introtodeeplearning.com/">MIT’s 6.S191: Intro to Deep Learning</a></li>
  <li><a href="https://www.youtube.com/playlist?list=PLLHTzKZzVU9eaEyErdV26ikyolxOsz6mq">NYU’s Deep Learning (Spring 2020)</a> by Alfredo Canziani</li>
  <li><a href="https://www.youtube.com/playlist?list=PL05umP7R6ij1tHaOFY96m5uX3J21a6yNd">University of Tübingen’s Probabilistic Machine Learning</a> by Philipp Hennig</li>
  <li><a href="https://www.youtube.com/playlist?list=PL_iWQOsE6TfVmKkQHucjPAoRtIJYt8a5A">Berkeley’s CS182: Deep Learning (Spring 2021)</a> by Sergey Levine</li>
  <li><a href="https://www.cs.princeton.edu/courses/archive/fall18/cos324/">Princeton’s COS324: Introduction to Machine Learning (Fall 2018)</a> by Ryan Adams</li>
  <li><a href="https://developers.google.com/machine-learning/crash-course/ml-intro">Google’s Machine Learning Crash Course</a></li>
  <li><a href="https://stanford.edu/~shervine/teaching/cs-229/">Stanford’s CS229: Machine Learning cliff notes</a> by Shervine and Afshine</li>
</ul>

<h2 id="one-off">ONE-OFF</h2>
<ul>
  <li><a href="https://www.youtube.com/watch?v=O5xeyoRL95U">MIT’s Deep Learning Basics (1 lecture)</a> by Lex Fridman</li>
  <li><a href="https://dlbasics.com/resources/Backpropagation/Chapter18PDF.pdf">Very gentle explanation of Backpropagation</a> by Andrew Glassner</li>
  <li><a href="https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi">3Blue1Brown’s 4 videos about NN’s</a></li>
</ul>

<h3 id="math-1">MATH</h3>
<ul>
  <li><a href="https://www.youtube.com/playlist?list=PL2SOU6wwxB0uwwH80KTQ6ht66KWxbzTIo">Harvard’s Stat 110</a> by Blitzstein</li>
</ul>

<hr width="100%" size="1" color="#DCDCDC" noshade="" />

<h2 id="transformers">TRANSFORMERS</h2>
<h3 id="blogswrite-ups">BLOGS/WRITE-UPS</h3>
<ul>
  <li><a href="https://theaisummer.com/transformer/">The AI Summer’s Attention blog post</a></li>
  <li><a href="https://huggingface.co/transformers/summary.html">HuggingFace’s hihg-level summary of various transformer models</a></li>
  <li><a href="https://nostalgebraist.tumblr.com/post/185326092369/1-classic-fully-connected-neural-networks-these">High-level, light-hearted blog post</a></li>
</ul>

<p><strong>Jay Alammar’s famous blog posts:</strong></p>
<ul>
  <li><a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/">Visualizing A Neural Machine Translation Model</a></li>
  <li><a href="https://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer</a></li>
  <li><a href="https://jalammar.github.io/illustrated-bert/">The Illustrated BERT, ELMo, and co</a></li>
</ul>

<h3 id="youtube">YOUTUBE</h3>
<ul>
  <li><a href="https://www.youtube.com/watch?v=FKlPCK1uFrc&amp;list=PLam9sigHPGwOBuH4_4fr-XvDbe5uneaf6&amp;index=3">Chris McCormick’s series about BERT</a></li>
  <li><a href="https://www.youtube.com/watch?v=rBCqOTEfxvg">The original authors of the Transformer present their paper</a></li>
  <li><a href="https://www.youtube.com/watch?v=OyFJWRnt_AY">Waterloo lecture on Attention and Transformers</a></li>
  <li><a href="https://www.youtube.com/watch?v=AFkGPmU16QA&amp;list=PLtmWHNX-gukKocXQOkQjuVxglSDYWsSh9">Fast.ai’s explanation of Key/Value/Query + code in the description</a></li>
</ul>

<h3 id="code">CODE</h3>
<ul>
  <li><a href="https://wandb.ai/cayush/simpletransformers/reports/Using-SimpleTransformers-for-Common-NLP-Applications--Vmlldzo4Njk2NA">Weights and Biases’ Transformer walkthrough</a></li>
  <li><a href="https://github.com/abhimishra91/transformers-tutorials">Someone’s PyTorch Transformers Tutorials</a></li>
</ul>

<hr width="100%" size="1" color="#DCDCDC" noshade="" />

<h2 id="other">OTHER</h2>
<ul>
  <li><a href="https://missing.csail.mit.edu/">MIT’s The Missing Semester</a> A great run-through of important computing tools and basics</li>
  <li><a href="https://wandb.ai/">Weights &amp; Biases</a> A phenomenal site that helps you keep track of many aspects of your ML experiments</li>
  <li><a href="https://robertheaton.com/2014/02/09/pythons-pass-by-object-reference-as-explained-by-philip-k-dick/">Understanding how Python handles functions</a></li>
</ul>

<p><strong>PyTorch:</strong></p>
<ul>
  <li><a href="https://pytorch.org/get-started/locally/">Getting Started</a></li>
  <li><a href="https://docs.microsoft.com/en-us/learn/paths/pytorch-fundamentals/">Microsoft’s PyTorch tutorial (4 modules)</a></li>
  <li><a href="https://pytorch.org/hub/huggingface_pytorch-transformers/">Transformers</a></li>
</ul>

  </div>
</article>

        </div>
      </div>

      <div class="wrapper-footer">
        <div class="container">
          <footer class="footer">
            
<a href="mailto:nlp-staff@mit.edu"><i class="svg-icon email"></i></a>













          </footer>
        </div>
      </div>
    </div>

    
	<!-- Google Analytics -->
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

		ga('create', '280781253', 'auto');
		ga('send', 'pageview', {
		  'page': '//supplemental',
		  'title': 'Supplemental Resources'
		});
	</script>
	<!-- End Google Analytics -->


  </body>
</html>
